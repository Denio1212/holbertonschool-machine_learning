{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Adds the evaluate func adapted for neural network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ff9f3607dcfb08b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "A neural network with one hidden layer performing binary classification\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    A neural network with one hidden layer performing binary classification\n",
    "    \"\"\"\n",
    "    def __init__(self, nx, nodes):\n",
    "        \"\"\"\n",
    "        nx is the number of input features\n",
    "\n",
    "        nodes is the number of nodes in the hidden layer\n",
    "\n",
    "        \"\"\"\n",
    "        if not isinstance(nx, int):\n",
    "            raise TypeError('nx must be an integer')\n",
    "        if nx < 1:\n",
    "            raise ValueError('nx must be a positive integer')\n",
    "        if not isinstance(nodes, int):\n",
    "            raise TypeError('nodes must be an integer')\n",
    "        if nodes < 1:\n",
    "            raise ValueError('nodes must be a positive integer')\n",
    "\n",
    "        self.__W1 = np.random.randn(nodes, nx)\n",
    "        self.__W2 = np.random.randn(1, nodes)\n",
    "        self.__b1 = np.zeros((nodes, 1))\n",
    "        self.__b2 = 0\n",
    "        self.__A1 = 0\n",
    "        self.__A2 = 0\n",
    "        \n",
    "    @property\n",
    "    def W1(self):\n",
    "        return self.__W1\n",
    "    \n",
    "    @property\n",
    "    def W2(self):\n",
    "        return self.__W2\n",
    "    \n",
    "    @property\n",
    "    def b1(self):\n",
    "        return self.__b1\n",
    "    \n",
    "    @property\n",
    "    def b2(self):\n",
    "        return self.__b2\n",
    "    \n",
    "    @property\n",
    "    def A1(self):\n",
    "        return self.__A1\n",
    "    \n",
    "    @property\n",
    "    def A2(self):\n",
    "        return self.__A2\n",
    "    \n",
    "    def forward_prop(self, X):\n",
    "        \"\"\"\n",
    "        Calculates the forward propagation of the neural network\n",
    "        :param X: array with shape (nx, m) with input data\n",
    "        nx is the number of input features\n",
    "        m is the number of examples\n",
    "        \"\"\"\n",
    "        z1 = np.matmul(self.__W1, X) + self.__b1\n",
    "        self.__A1 = 1 / (1 + np.exp(-z1))\n",
    "        z2 = np.matmul(self.__W2, self.__A1) + self.__b2\n",
    "        self.__A2 = 1 / (1 + np.exp(-z2))\n",
    "        return self.__A1, self.__A2\n",
    "\n",
    "    def cost(self, Y, A):\n",
    "        \"\"\"\n",
    "        Calculates the cost of the model using logistic regression\n",
    "        :param Y: array with shape (1, m) with correct labels for input data\n",
    "        :param A: array with shape (1, m) with activated  outputs\n",
    "        for each example\n",
    "        To avoid division by zero errors, we will use\n",
    "        1.0000001 - A instead of 1 - A\n",
    "        \"\"\"\n",
    "        m = Y.shape[1]\n",
    "        m_loss = np.sum(( Y * np.log(A) + (1 - Y) * np.log((1.0000001 - A)) ))\n",
    "        costs = (1 / m) *  (-m_loss)\n",
    "        return costs\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "         \"\"\"\n",
    "         evaluates the neural network's predictions\n",
    "         :param X: array with shape (nx, m) with input data\n",
    "         nx is the number of input features in the neuron\n",
    "         m is the number of examples\n",
    "         :param Y: array with shape (1, m) with correct labels for input data\n",
    "         \"\"\"\n",
    "         A1, A2 = self.forward_prop(X)\n",
    "         cost = self.cost(Y, A2)\n",
    "         predictions = np.where(A2 >= 0.5, 1, 0)\n",
    "         return predictions, cost\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:59:20.278071Z",
     "start_time": "2024-03-27T11:59:20.268507Z"
    }
   },
   "id": "27875fbfaba5c311",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7917984405648547\n"
     ]
    }
   ],
   "source": [
    "# Main func\n",
    "\n",
    "NN = NeuralNetwork\n",
    "\n",
    "lib_train = np.load('../data/Binary_Train.npz')\n",
    "X_3D, Y = lib_train['X'], lib_train['Y']\n",
    "X = X_3D.reshape((X_3D.shape[0], -1)).T\n",
    "\n",
    "np.random.seed(0)\n",
    "nn = NN(X.shape[0], 3)\n",
    "A, cost = nn.evaluate(X, Y)\n",
    "print(A)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:59:20.704297Z",
     "start_time": "2024-03-27T11:59:20.473761Z"
    }
   },
   "id": "985f05dbada16c65",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3742276d942c9622"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
