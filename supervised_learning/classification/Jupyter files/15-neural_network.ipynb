{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:20:32.133167Z",
     "start_time": "2024-04-03T17:20:31.978406Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Class NeuralNetwork that defines a neural network\n",
    "with one hidden layer performing binary classification\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    A single neuron performing binary classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nx, nodes):\n",
    "        \"\"\"\n",
    "        class constructor\n",
    "        \"\"\"\n",
    "        if type(nx) is not int:\n",
    "            raise TypeError(\"nx must be an integer\")\n",
    "        if nx < 1:\n",
    "            raise ValueError(\"nx must be a positive integer\")\n",
    "        if type(nodes) is not int:\n",
    "            raise TypeError(\"nodes must be an integer\")\n",
    "        if nodes < 1:\n",
    "            raise ValueError(\"nodes must be a positive integer\")\n",
    "\n",
    "        self.__W1 = np.random.randn(nodes, nx)\n",
    "        self.__b1 = np.zeros((nodes, 1))\n",
    "        self.__A1 = 0\n",
    "        self.__W2 = np.random.randn(1, nodes)\n",
    "        self.__b2 = 0\n",
    "        self.__A2 = 0\n",
    "\n",
    "    @property\n",
    "    def W1(self):\n",
    "        \"\"\" get method for property W1\"\"\"\n",
    "        return self.__W1\n",
    "\n",
    "    @property\n",
    "    def b1(self):\n",
    "        \"\"\" get method for property b1\"\"\"\n",
    "        return self.__b1\n",
    "\n",
    "    @property\n",
    "    def A1(self):\n",
    "        \"\"\" get method for property A1\"\"\"\n",
    "        return self.__A1\n",
    "\n",
    "    @property\n",
    "    def W2(self):\n",
    "        \"\"\" get method for property W2\"\"\"\n",
    "        return self.__W2\n",
    "\n",
    "    @property\n",
    "    def b2(self):\n",
    "        \"\"\" get method for property b2\"\"\"\n",
    "        return self.__b2\n",
    "\n",
    "    @property\n",
    "    def A2(self):\n",
    "        \"\"\" get method for property A2\"\"\"\n",
    "        return self.__A2\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        \"\"\" Calculates the forward propagation of the neural network \"\"\"\n",
    "        z1 = np.matmul(self.W1, X) + self.b1\n",
    "        self.__A1 = 1 / (1 + (np.exp(-z1)))\n",
    "        z2 = np.matmul(self.W2, self.A1) + self.b2\n",
    "        self.__A2 = 1 / (1 + (np.exp(-z2)))\n",
    "        return (self.__A1, self.__A2)\n",
    "\n",
    "    def cost(self, Y, A):\n",
    "        \"\"\"\n",
    "        calculates the cost of the model using logistic regression\n",
    "        \"\"\"\n",
    "        m = Y.shape[1]\n",
    "        m_loss = np.sum((Y * np.log(A)) + ((1 - Y) * np.log(1.0000001 - A)))\n",
    "        cost = (1 / m) * (-(m_loss))\n",
    "        return (cost)\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"\n",
    "        evaluates the neuron's predictions\n",
    "        \"\"\"\n",
    "        A1, A2 = self.forward_prop(X)\n",
    "        cost = self.cost(Y, A2)\n",
    "        prediction = np.where(A2 >= 0.5, 1, 0)\n",
    "        return (prediction, cost)\n",
    "\n",
    "    def gradient_descent(self, X, Y, A1, A2, alpha=0.05):\n",
    "        \"\"\" gradient descent algorithm for neural network \"\"\"\n",
    "        m = Y.shape[1]\n",
    "\n",
    "        dz2 = (A2 - Y)\n",
    "        d__W2 = (1 / m) * (np.matmul(dz2, A1.transpose()))\n",
    "        d__b2 = (1 / m) * (np.sum(dz2, axis=1, keepdims=True))\n",
    "\n",
    "        dz1 = (np.matmul(self.W2.transpose(), dz2)) * (A1 * (1 - A1))\n",
    "        d__W1 = (1 / m) * (np.matmul(dz1, X.transpose()))\n",
    "        d__b1 = (1 / m) * (np.sum(dz1, axis=1, keepdims=True))\n",
    "\n",
    "        self.__W2 = self.W2 - (alpha * d__W2)\n",
    "        self.__b2 = self.b2 - (alpha * d__b2)\n",
    "        self.__W1 = self.W1 - (alpha * d__W1)\n",
    "        self.__b1 = self.b1 - (alpha * d__b1)\n",
    "\n",
    "    def train(self, X, Y, iterations=5000, alpha=0.05,\n",
    "              verbose=True, graph=True, step=100):\n",
    "        \"\"\"\n",
    "        trains the neuron and updates __W, __b, and __A\n",
    "        \"\"\"\n",
    "        if type(iterations) is not int:\n",
    "            raise TypeError(\"iterations must be an integer\")\n",
    "        if iterations <= 0:\n",
    "            raise ValueError(\"iterations must be a positive integer\")\n",
    "        if type(alpha) is not float:\n",
    "            raise TypeError(\"alpha must be a float\")\n",
    "        if alpha <= 0:\n",
    "            raise ValueError(\"alpha must be positive\")\n",
    "        if verbose or graph:\n",
    "            if type(step) is not int:\n",
    "                raise TypeError(\"step must be an integer\")\n",
    "            if step <= 0 or step > iterations:\n",
    "                raise ValueError(\"step must be positive and <= iterations\")\n",
    "        if graph:\n",
    "            import matplotlib.pyplot as plt\n",
    "            x_points = np.arange(0, iterations + 1, step)\n",
    "            points = []\n",
    "        for itr in range(iterations):\n",
    "            A1, A2 = self.forward_prop(X)\n",
    "            if verbose and (itr % step) == 0:\n",
    "                cost = self.cost(Y, A2)\n",
    "                print(\"Cost after \" + str(itr) + \" iterations: \" + str(cost))\n",
    "            if graph and (itr % step) == 0:\n",
    "                cost = self.cost(Y, A2)\n",
    "                points.append(cost)\n",
    "            self.gradient_descent(X, Y, A1, A2, alpha)\n",
    "        itr += 1\n",
    "        if verbose:\n",
    "            cost = self.cost(Y, A2)\n",
    "            print(\"Cost after \" + str(itr) + \" iterations: \" + str(cost))\n",
    "        if graph:\n",
    "            cost = self.cost(Y, A2)\n",
    "            points.append(cost)\n",
    "            y_points = np.asarray(points)\n",
    "            plt.plot(x_points, y_points, 'b')\n",
    "            plt.xlabel(\"iteration\")\n",
    "            plt.ylabel(\"cost\")\n",
    "            plt.title(\"Training Cost\")\n",
    "            plt.show()\n",
    "        return self.evaluate(X, Y)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 iterations: 0.7917984405648547\n",
      "Cost after 100 iterations: 0.4680930945144984\n",
      "Cost after 200 iterations: 0.36421845131233044\n",
      "Cost after 300 iterations: 0.29373147773402275\n",
      "Cost after 400 iterations: 0.24674864741137867\n",
      "Cost after 500 iterations: 0.21176811241220997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     13\u001B[0m nn \u001B[38;5;241m=\u001B[39m NN(X_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m A, cost \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(A \u001B[38;5;241m==\u001B[39m Y_train) \u001B[38;5;241m/\u001B[39m Y_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrain cost:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cost)\n",
      "Cell \u001B[1;32mIn[1], line 132\u001B[0m, in \u001B[0;36mNeuralNetwork.train\u001B[1;34m(self, X, Y, iterations, alpha, verbose, graph, step)\u001B[0m\n\u001B[0;32m    130\u001B[0m     points \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m itr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(iterations):\n\u001B[1;32m--> 132\u001B[0m     A1, A2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_prop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m verbose \u001B[38;5;129;01mand\u001B[39;00m (itr \u001B[38;5;241m%\u001B[39m step) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    134\u001B[0m         cost \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcost(Y, A2)\n",
      "Cell \u001B[1;32mIn[1], line 68\u001B[0m, in \u001B[0;36mNeuralNetwork.forward_prop\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_prop\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m     67\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" Calculates the forward propagation of the neural network \"\"\"\u001B[39;00m\n\u001B[1;32m---> 68\u001B[0m     z1 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb1\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__A1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m (np\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241m-\u001B[39mz1)))\n\u001B[0;32m     70\u001B[0m     z2 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmatmul(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW2, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mA1) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb2\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Main Func\n",
    "\n",
    "NN = NeuralNetwork\n",
    "\n",
    "lib_train = np.load('../data/Binary_Train.npz')\n",
    "X_train_3D, Y_train = lib_train['X'], lib_train['Y']\n",
    "X_train = X_train_3D.reshape((X_train_3D.shape[0], -1)).T\n",
    "lib_dev = np.load('../data/Binary_Dev.npz')\n",
    "X_dev_3D, Y_dev = lib_dev['X'], lib_dev['Y']\n",
    "X_dev = X_dev_3D.reshape((X_dev_3D.shape[0], -1)).T\n",
    "\n",
    "np.random.seed(0)\n",
    "nn = NN(X_train.shape[0], 3)\n",
    "A, cost = nn.train(X_train, Y_train)\n",
    "accuracy = np.sum(A == Y_train) / Y_train.shape[1] * 100\n",
    "print(\"Train cost:\", cost)\n",
    "print(\"Train accuracy: {}%\".format(accuracy))\n",
    "A, cost = nn.evaluate(X_dev, Y_dev)\n",
    "accuracy = np.sum(A == Y_dev) / Y_dev.shape[1] * 100\n",
    "print(\"Dev cost:\", cost)\n",
    "print(\"Dev accuracy: {}%\".format(accuracy))\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    fig.add_subplot(10, 10, i + 1)\n",
    "    plt.imshow(X_dev_3D[i])\n",
    "    plt.title(A[0, i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-03T17:20:32.135179Z"
    }
   },
   "id": "f551ed2c5d2fac00",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-03T17:21:43.081007Z"
    }
   },
   "id": "211ecd42abd606aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
