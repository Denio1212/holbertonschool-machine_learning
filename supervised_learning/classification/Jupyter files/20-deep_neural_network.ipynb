{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:26:42.844177Z",
     "start_time": "2024-04-03T17:26:42.833101Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "The Neural Network Deepens\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DeepNeuralNetwork:\n",
    "    \"\"\"\n",
    "    The Deep Neural Network\n",
    "    \"\"\"\n",
    "    def __init__(self, nx, layers):\n",
    "        \"\"\"\n",
    "        Initializes the Deep Neural Network\n",
    "        \"\"\"\n",
    "        if not isinstance(nx, int):\n",
    "            raise TypeError('nx must be an integer')\n",
    "        if nx < 1:\n",
    "            raise ValueError('nx must be a positive integer')\n",
    "        if not isinstance(layers, list) or len(layers) == 0:\n",
    "            raise TypeError('layers must be a list of positive integers')\n",
    "        \n",
    "        weights = {}\n",
    "        previous = nx\n",
    "        \n",
    "        for index, layer in enumerate(layers, 1):\n",
    "            if not isinstance(layer, int) or layer < 1:\n",
    "                raise TypeError('layers must be a list of positive integers')\n",
    "            \n",
    "            weights[\"b{}\".format(index)] = np.zeros((layer, 1))      \n",
    "            weights[\"W{}\".format(index)] = (np.random.randn(layer, previous) *\n",
    "                                            np.sqrt(2 / previous))\n",
    "            previous = layer\n",
    "            \n",
    "        self.__L = len(layers)\n",
    "        self.__cache = {}\n",
    "        self.__weights = weights\n",
    "        \n",
    "    @property\n",
    "    def L(self):\n",
    "        return self.__L\n",
    "    \n",
    "    @property\n",
    "    def cache(self):\n",
    "        return self.__cache\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self.__weights\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        \"\"\"\n",
    "        Calculates the forward propagation of the neural network\n",
    "        :param X: array with shape (nx, m) with input data\n",
    "        nx is the number of input features\n",
    "        m is the number of examples\n",
    "        \"\"\"\n",
    "        self.__cache[\"A0\"] = X\n",
    "        \n",
    "        for index in range(self.L):\n",
    "            W = self.weights[\"W{}\".format(index + 1)]\n",
    "            b = self.weights[\"b{}\".format(index + 1)]\n",
    "            \n",
    "            z = np.matmul(W, self.cache[\"A{}\".format(index)]) + b\n",
    "            a = 1 / (1 + np.exp(-z))\n",
    "            \n",
    "            self.__cache[\"A{}\".format(index + 1)] = a\n",
    "        return a, self.cache\n",
    "    \n",
    "    def cost(self, Y, A):\n",
    "        \"\"\"\n",
    "        Calculates the cost of the model using logistic regression\n",
    "        :param Y: array with shape (1, m) with correct labels for input data\n",
    "        :param A: array with shape (1, m) with activated  outputs\n",
    "        for each example\n",
    "        To avoid division by zero errors, we will use\n",
    "        1.0000001 - A instead of 1 - A\n",
    "        \"\"\"\n",
    "        m = Y.shape[1]\n",
    "        m_loss = np.sum(( Y * np.log(A) + (1 - Y) * np.log((1.0000001 - A)) ))\n",
    "        costs = (1 / m) *  (-m_loss)\n",
    "        return costs\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"\n",
    "        Evaluates the deep neural network\n",
    "        \"\"\"\n",
    "        A, cache = self.forward_prop(X)\n",
    "        cost = self.cost(Y, A)\n",
    "        predictions = np.where(A >= 0.5, 1, 0)\n",
    "        return predictions, cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 1 1 1]]\n",
      "0.6958649419170609\n"
     ]
    }
   ],
   "source": [
    "Deep = DeepNeuralNetwork\n",
    "\n",
    "lib_train = np.load('../data/Binary_Train.npz')\n",
    "X_3D, Y = lib_train['X'], lib_train['Y']\n",
    "X = X_3D.reshape((X_3D.shape[0], -1)).T\n",
    "\n",
    "np.random.seed(0)\n",
    "deep = Deep(X.shape[0], [5, 3, 1])\n",
    "A, cost = deep.evaluate(X, Y)\n",
    "print(A)\n",
    "print(cost)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:26:57.628929Z",
     "start_time": "2024-04-03T17:26:57.421670Z"
    }
   },
   "id": "93f57b2905e34a56",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e71c0fd4b403cf72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
