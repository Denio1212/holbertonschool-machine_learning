{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:09:12.152710Z",
     "start_time": "2024-03-28T17:09:12.142824Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "The Neural Network Deepens\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DeepNeuralNetwork:\n",
    "    \"\"\"\n",
    "    The Deep Neural Network\n",
    "    \"\"\"\n",
    "    def __init__(self, nx, layers):\n",
    "        \"\"\"\n",
    "        Initializes the Deep Neural Network\n",
    "        \"\"\"\n",
    "        if not isinstance(nx, int):\n",
    "            raise TypeError('nx must be an integer')\n",
    "        if nx < 1:\n",
    "            raise ValueError('nx must be a positive integer')\n",
    "        if not isinstance(layers, list) or len(layers) == 0:\n",
    "            raise TypeError('layers must be a list of positive integers')\n",
    "        \n",
    "        weights = {}\n",
    "        previous = nx\n",
    "        \n",
    "        for index, layer in enumerate(layers, 1):\n",
    "            if not isinstance(layer, int) or layer < 1:\n",
    "                raise TypeError('layers must be a list of positive integers')\n",
    "            \n",
    "            weights[\"b{}\".format(index)] = np.zeros((layer, 1))      \n",
    "            weights[\"W{}\".format(index)] = (np.random.randn(layer, previous) *\n",
    "                                            np.sqrt(2 / previous))\n",
    "            previous = layer\n",
    "            \n",
    "        self.__L = len(layers)\n",
    "        self.__cache = {}\n",
    "        self.__weights = weights\n",
    "        \n",
    "    @property\n",
    "    def L(self):\n",
    "        return self.__L\n",
    "    \n",
    "    @property\n",
    "    def cache(self):\n",
    "        return self.__cache\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self.__weights\n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        \"\"\"\n",
    "        Calculates the forward propagation of the neural network\n",
    "        :param X: array with shape (nx, m) with input data\n",
    "        nx is the number of input features\n",
    "        m is the number of examples\n",
    "        \"\"\"\n",
    "        self.__cache[\"A0\"] = X\n",
    "        \n",
    "        for index in range(self.L):\n",
    "            W = self.weights[\"W{}\".format(index + 1)]\n",
    "            b = self.weights[\"b{}\".format(index + 1)]\n",
    "            \n",
    "            z = np.matmul(W, self.cache[\"A{}\".format(index)]) + b\n",
    "            a = 1 / (1 + np.exp(-z))\n",
    "            \n",
    "            self.__cache[\"A{}\".format(index + 1)] = a\n",
    "        return a, self.cache\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75603476 0.7516025  0.75526716 ... 0.75228888 0.75522853 0.75217069]]\n",
      "{'A0': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'A1': array([[0.4678435 , 0.64207147, 0.55271425, ..., 0.61718097, 0.56412986,\n",
      "        0.72751504],\n",
      "       [0.79441392, 0.87140579, 0.72851107, ..., 0.8898201 , 0.79466389,\n",
      "        0.82257068],\n",
      "       [0.72337339, 0.68239373, 0.63526533, ..., 0.7036234 , 0.7770501 ,\n",
      "        0.69465346],\n",
      "       [0.65305735, 0.69829955, 0.58646313, ..., 0.73949722, 0.52054315,\n",
      "        0.73151973],\n",
      "       [0.67408798, 0.69624537, 0.73084352, ..., 0.70663173, 0.76204175,\n",
      "        0.72705428]]), 'A2': array([[0.75067742, 0.78319533, 0.77755571, ..., 0.77891002, 0.75847839,\n",
      "        0.78517215],\n",
      "       [0.70591081, 0.71159364, 0.7362214 , ..., 0.70845465, 0.72133875,\n",
      "        0.71090691],\n",
      "       [0.72032379, 0.69519095, 0.72414599, ..., 0.70067751, 0.71161433,\n",
      "        0.70420437]]), 'A3': array([[0.75603476, 0.7516025 , 0.75526716, ..., 0.75228888, 0.75522853,\n",
      "        0.75217069]])}\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# MAin func\n",
    "\n",
    "Deep = DeepNeuralNetwork\n",
    "\n",
    "lib_train = np.load('../data/Binary_Train.npz')\n",
    "X_3D, Y = lib_train['X'], lib_train['Y']\n",
    "X = X_3D.reshape((X_3D.shape[0], -1)).T\n",
    "\n",
    "np.random.seed(0)\n",
    "deep = Deep(X.shape[0], [5, 3, 1])\n",
    "deep._DeepNeuralNetwork__weights['b1'] = np.ones((5, 1))\n",
    "deep._DeepNeuralNetwork__weights['b2'] = np.ones((3, 1))\n",
    "deep._DeepNeuralNetwork__weights['b3'] = np.ones((1, 1))\n",
    "A, cache = deep.forward_prop(X)\n",
    "print(A)\n",
    "print(cache)\n",
    "print(cache is deep.cache)\n",
    "print(A is cache['A3'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T17:09:12.680158Z",
     "start_time": "2024-03-28T17:09:12.514266Z"
    }
   },
   "id": "619d6772a4618278",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "303761067ee62ec5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
