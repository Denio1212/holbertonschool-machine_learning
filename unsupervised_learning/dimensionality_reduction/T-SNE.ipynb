{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "date: 2024-09-15 10:47:37\n",
    "created: 2024-09-15 09:48:07\n",
    "categories:\n",
    "- School Stuff / Unsupervised Learning\n",
    "---\n",
    "\n",
    "## #T\\_SNE\n",
    "\n",
    "  \n",
    "\n",
    "# t-Distributed Stochastic Neighbor Embedding (t-SNE)\\\\\n",
    "\n",
    "  \n",
    "\n",
    "t-sne is a ⁠Dimensionality Reduction ⁠technique that is particularly good at visualizing/turning high dimensional data ⁠into low dimension data ⁠(particularly 2D and 3D)\n",
    "\n",
    "It is better than ⁠PCA ⁠at keeping local relationships between data points, and ⁠t-sne⁠ captures non-linear patterns and ⁠clusters a whole lot more efficiently than ⁠PCA⁠.\n",
    "\n",
    "  \n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "  \n",
    "\n",
    "- ⁠Local Relations: ⁠t-sne ⁠tries to keep neighboring data in high dimensions close when formatting to a low dimension\n",
    "\n",
    "  \n",
    "\n",
    "⁠\n",
    "\n",
    "- ⁠⁠Non-Linearity: ⁠It captures more complex relationships than ⁠PCA ⁠by focusing on **preserving local clusters and neighborhoods**, which is great for non-linear data (Images or Word Embeddings)\n",
    "\n",
    "  \n",
    "\n",
    "- ⁠Visualization: ⁠⁠t-sne⁠ is really useful when visualizing large/complex datasets with many dimensions, since it is efficient at turning those datasets into 2D or 3D for plotting purposes.\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "### Steps in Application:\n",
    "\n",
    "  \n",
    "\n",
    "1.  **Pairwise Similarities:** It calculates the similarity between points in the original high dimensional space.\n",
    "\n",
    "⁠  \n",
    "\n",
    "2. **Probability Distribution: t-Sne** converts the similarities paired above into a ⁠Probability Distribution⁠.\n",
    "\n",
    "  \n",
    "\n",
    "3. **Minimizing Divergence:** It then basically **_Dr. Stranges_** it’s way into finding a low dimensional embedding ⁠where the **Pairwise Similarities** are as close as possible to those in the beeg space.\n",
    "\n",
    "  \n",
    "\n",
    "### T-SNE in Python\n",
    "\n",
    "We will take the mnist dataset with 784 dimensions and visualize it into a 2D plot using T-SNE\n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "`⁠pip install scikit-learn matplotlib`⁠\n",
    "\n",
    "  \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load the digits dataset (handwritten digits)\n",
    "digits = load_digits()\n",
    "X = digits.data  # The 64-dimensional data points\n",
    "y = digits.target  # The labels (0-9)\n",
    "\n",
    "# Step 2: Standardize the data (important for t-SNE)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Apply t-SNE to reduce the data to 2 dimensions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Step 4: Plot the data in 2D using matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10')\n",
    "plt.colorbar(scatter, ticks=range(10))  # Add colorbar to show digit labels\n",
    "plt.title(\"t-SNE visualization of MNIST Digits\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "  \n",
    "\n",
    "- The following plot will show a 2D representation of the relationships where similar digits form clusters together.\n",
    "- This is a visual representation of the relationships between the digits in the og high dimensional space in 2D for easy interpretation"
   ],
   "id": "57304c90cef251e6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Task 1 of T-SNE. The init.",
   "id": "d4f9a827612e523b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T09:12:14.459294Z",
     "start_time": "2024-09-15T09:12:14.246404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Initializes all variables required for to calculate the P affinities in T-sne\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def P_init(X, perplexity):\n",
    "    \"\"\"\n",
    "    Initializes all variables required for to calculate the P affinities in T-sne\n",
    "    \n",
    "    Parameters:\n",
    "        X is a numpy.ndarray of shape (n, d) containing the dataset\n",
    "        to be transformed by t-SNE\n",
    "            -> n is the number of data points\n",
    "            -> d is the number of dimensions in each point\n",
    "        \n",
    "        perplexity is the perplexity that all Gaussian distributions have\n",
    "    \n",
    "    Returns:\n",
    "        (D, P, betas, H)\n",
    "            -> D: a numpy.ndarray of shape (n, n) that calculates\n",
    "            the squared pairwise distance between two data points\n",
    "                * The diagonal of D should be 0s\n",
    "            \n",
    "            -> P: a numpy.ndarray of shape (n, n) initialized to all 0‘s that\n",
    "            will contain the P affinities \n",
    "            \n",
    "            -> betas: a numpy.ndarray of shape (n, 1) initialized to all 1’s\n",
    "            that will contain all of the beta values\n",
    "            \n",
    "            \n",
    "            -> H is the Shannon entropy for perplexity perplexity with a base of 2\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    X_sum = np.sum(np.square(X), axis=1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), X_sum).T, X_sum)\n",
    "    np.fill_diagonal(D, 0)\n",
    "    \n",
    "    P = np.zeros((n, n))\n",
    "    \n",
    "    betas = np.ones((n, 1))\n",
    "    \n",
    "    H = np.log2(perplexity)\n",
    "    \n",
    "    return D, P, betas, H\n",
    "    "
   ],
   "id": "bae8094699e5aa4d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T09:12:44.617476Z",
     "start_time": "2024-09-15T09:12:44.503469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main file\n",
    "\n",
    "\n",
    "pca = __import__('1-pca').pca\n",
    "\n",
    "X = np.loadtxt(\"data/mnist2500_X.txt\")\n",
    "X = pca(X, 50)\n",
    "D, P, betas, H = P_init(X, 30.0)\n",
    "print('X:', X.shape)\n",
    "print(X)\n",
    "print('D:', D.shape)\n",
    "print(D.round(2))\n",
    "print('P:', P.shape)\n",
    "print(P)\n",
    "print('betas:', betas.shape)\n",
    "print(betas)\n",
    "print('H:', H)"
   ],
   "id": "eea2d05f8b5ecc7a",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the number of columns changed from 784 to 535 at row 669; use `usecols` to select a subset and avoid this error",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# main file\u001B[39;00m\n\u001B[0;32m      4\u001B[0m pca \u001B[38;5;241m=\u001B[39m \u001B[38;5;28m__import__\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1-pca\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mpca\n\u001B[1;32m----> 6\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadtxt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/mnist2500_X.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m X \u001B[38;5;241m=\u001B[39m pca(X, \u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      8\u001B[0m D, P, betas, H \u001B[38;5;241m=\u001B[39m P_init(X, \u001B[38;5;241m30.0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\holbertonschool-machine_learning\\venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:1373\u001B[0m, in \u001B[0;36mloadtxt\u001B[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001B[0m\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(delimiter, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m   1371\u001B[0m     delimiter \u001B[38;5;241m=\u001B[39m delimiter\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1373\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1374\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiplines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1375\u001B[0m \u001B[43m            \u001B[49m\u001B[43munpack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munpack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mndmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1376\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1378\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\n",
      "File \u001B[1;32m~\\PycharmProjects\\holbertonschool-machine_learning\\venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:1016\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001B[0m\n\u001B[0;32m   1013\u001B[0m     data \u001B[38;5;241m=\u001B[39m _preprocess_comments(data, comments, encoding)\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m read_dtype_via_object_chunks \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1016\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43m_load_from_filelike\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1018\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimaginary_unit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimaginary_unit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1019\u001B[0m \u001B[43m        \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiplines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiplines\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1020\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1021\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilelike\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilelike\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1022\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbyte_converters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbyte_converters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1025\u001B[0m     \u001B[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001B[39;00m\n\u001B[0;32m   1026\u001B[0m     \u001B[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001B[39;00m\n\u001B[0;32m   1027\u001B[0m     \u001B[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001B[39;00m\n\u001B[0;32m   1028\u001B[0m     \u001B[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m filelike:\n",
      "\u001B[1;31mValueError\u001B[0m: the number of columns changed from 784 to 535 at row 669; use `usecols` to select a subset and avoid this error"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4c02551c89457ea2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
