{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Gaussian Mixture model\n",
    "\n",
    " Unlike methods like K-Means, which assign each point to a single cluster, GMM gives a probability for each point to belong to different clusters, making it more flexible for complex datasets where clusters may overlap or have different shapes."
   ],
   "id": "ae17b2ffd12394ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 4, Initializing the GMM\n",
    "\n",
    "* X is a numpy.ndarray of shape (n, d) containing the data set\n",
    "- k is a positive integer containing the number of cluster\n",
    "* You are not allowed to use any loops\n",
    "- Returns: pi, m, S, or None, None, None on failure\n",
    "pi is a numpy.ndarray of shape (k,) containing the priors for each cluster, initialized evenly\n",
    "m is a numpy.ndarray of shape (k, d) containing the centroid means for each cluster, initialized with K-means\n",
    "S is a numpy.ndarray of shape (k, d, d) containing the covariance matrices for each cluster, initialized as identity matrices"
   ],
   "id": "e869f87f872241ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:05.369577Z",
     "start_time": "2024-09-23T14:32:04.171377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.covariance import log_likelihood\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Initializes variables for a Gaussian mixture model.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "kmeans = __import__('1-kmeans').kmeans\n",
    "\n",
    "\n",
    "def initialize(X, k):\n",
    "    \"\"\"\n",
    "    Initializes variables for a Gaussian Mixture Mode\n",
    "    \"\"\"\n",
    "    if not isinstance(X, np.ndarray) or len(X.shape) != 2:\n",
    "        return None, None, None\n",
    "    if not isinstance(k, int) or k < 1:\n",
    "        return None, None, None\n",
    "    \n",
    "    n, d = X.shape\n",
    "    \n",
    "    phi = np.ones(k) / k\n",
    "    \n",
    "    m, _ = kmeans(X, k)\n",
    "    \n",
    "    S = np.tile(np.identity(d), (k, 1)).reshape(k, d, d)\n",
    "    \n",
    "    return phi, m, S\n"
   ],
   "id": "dc4ead0dcee8499e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:05.588779Z",
     "start_time": "2024-09-23T14:32:05.381587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main func\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(11)\n",
    "    a = np.random.multivariate_normal([30, 40], [[75, 5], [5, 75]], size=10000)\n",
    "    b = np.random.multivariate_normal([5, 25], [[16, 10], [10, 16]], size=750)\n",
    "    c = np.random.multivariate_normal([60, 30], [[16, 0], [0, 16]], size=750)\n",
    "    d = np.random.multivariate_normal([20, 70], [[35, 10], [10, 35]], size=1000)\n",
    "    X = np.concatenate((a, b, c, d), axis=0)\n",
    "    np.random.shuffle(X)\n",
    "    pi, m, S = initialize(X, 4)\n",
    "    print(pi)\n",
    "    print(m)\n",
    "    print(S)"
   ],
   "id": "2b6d0983b137fe46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.25 0.25 0.25]\n",
      "[[54.73711515 31.81393242]\n",
      " [16.84012557 31.20248225]\n",
      " [21.43215816 65.50449077]\n",
      " [32.3301925  41.80664127]]\n",
      "[[[1. 0.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[1. 0.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[1. 0.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[1. 0.]\n",
      "  [0. 1.]]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PDF\n",
    "\n",
    "Calculates the probability density function of a Gaussian distribution\n",
    "\n",
    "* X is a numpy.ndarray of shape (n, d) containing the data points whose PDF should be evaluated\n",
    "- m is a numpy.ndarray of shape (d,) containing the mean of the distribution\n",
    "* You are not allowed to use any loops\n",
    "- You are not allowed to use the function numpy.diag or the method numpy.ndarray.diagonal\n",
    "* Returns: P, or None on failure\n",
    "P is a numpy.ndarray of shape (n,) containing the PDF values for each data point\n",
    "- All values in P should have a minimum value of 1e-300"
   ],
   "id": "faadd81faf8fd693"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:05.627455Z",
     "start_time": "2024-09-23T14:32:05.620269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"PDF function \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pdf(X, m, S):\n",
    "    \"\"\"\n",
    "    Probability Density Function of gaussian distributions\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(X, np.ndarray) or len(X.shape) != 2:\n",
    "        return None\n",
    "    if not isinstance(m, np.ndarray) or len(m.shape) != 1:\n",
    "        return None\n",
    "    if not isinstance(S, np.ndarray) or len(S.shape) != 2:\n",
    "        return None\n",
    "    if X.shape[1] != m.shape[0] or X.shape[1] != S.shape[0]:\n",
    "        return None\n",
    "    if S.shape[0] != S.shape[1]:\n",
    "        return None\n",
    "\n",
    "    # formula\n",
    "    # p(x∣ μ,Σ) = (1 √(2π)d|Σ|)exp(−1/2(x−μ)T Σ−1(x−μ))\n",
    "    n, d = X.shape\n",
    "    mean = m\n",
    "    x_m = X - mean\n",
    "\n",
    "    # Determinant of the covariance matrix (d x d)\n",
    "    det_S = np.linalg.det(S)\n",
    "\n",
    "    # Since Σ is Hermitian, it has an eigendecomposition\n",
    "    inv_S = np.linalg.inv(S)\n",
    "\n",
    "    # Formula Section one: (1 √(2π)d|Σ|)\n",
    "    part_1_dem = np.sqrt(det_S) * ((2 * np.pi) ** (d/2))\n",
    "\n",
    "    # Formula Section two_upper_1: −1/2(x−μ)T\n",
    "    part_2 = np.matmul(x_m, inv_S)\n",
    "\n",
    "    # Formula Section two_upper_2: Σ−1(x−μ) used diagonal to fix alloc err\n",
    "    part_2_1 = np.sum(x_m * part_2, axis=1)\n",
    "\n",
    "    # Formula Section two exp(−1/2(x−μ)T Σ−1(x−μ))\n",
    "    part_2_2 = np.exp(part_2_1 / -2)\n",
    "\n",
    "    # pdf = part_1 * part_2_2:\n",
    "    pdf = part_2_2 / part_1_dem\n",
    "    P = np.where(pdf < 1e-300, 1e-300, pdf)\n",
    "    return P"
   ],
   "id": "1319b6420ff42148",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:05.667604Z",
     "start_time": "2024-09-23T14:32:05.654449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main func\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(0)\n",
    "    m = np.array([12, 30, 10])\n",
    "    S = np.array([[36, -30, 15], [-30, 100, -20], [15, -20, 25]])\n",
    "    X = np.random.multivariate_normal(m, S, 10000)\n",
    "    P = pdf(X, m, S)\n",
    "    print(P)"
   ],
   "id": "da1a25a293914bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.47450910e-05 2.53649178e-06 1.80348301e-04 ... 1.24604061e-04\n",
      " 1.86345129e-04 2.59397003e-05]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PDF expectation step\n",
    "\n",
    "* Calculates the expectation step in the EM algorithm for a GMM\n",
    "- X is a numpy.ndarray of shape (n, d) containing the data set\n",
    "* pi is a numpy.ndarray of shape (k,) containing the priors for each cluster\n",
    "- m is a numpy.ndarray of shape (k, d) containing the centroid means for each cluster\n",
    "* S is a numpy.ndarray of shape (k, d, d) containing the covariance matrices for each cluster\n",
    "* 1 loop is allowed at most\n",
    "- Returns: g, l, or None, None on failure\n",
    "\n",
    "* g is a numpy.ndarray of shape (k, n) containing the posterior probabilities for each data point in each cluster\n",
    "l is the total log likelihood"
   ],
   "id": "946bc8f1ad63ab4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:05.721230Z",
     "start_time": "2024-09-23T14:32:05.709755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Calculates the expectation step in the EM algorithm for a GMM\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "pdf = __import__('5-pdf').pdf\n",
    "\n",
    "\n",
    "\n",
    "def expectation(X, pi, m, S):\n",
    "    \"\"\"\n",
    "    calculates the expectation step for a Gaussian mixture model\n",
    "    \"\"\"\n",
    "    if not isinstance(X, np.ndarray) or len(X.shape) != 2:\n",
    "        return None, None\n",
    "    if not isinstance(m, np.ndarray) or len(m.shape) != 2:\n",
    "        return None, None\n",
    "    if not isinstance(pi, np.ndarray) or len(pi.shape) != 1:\n",
    "        return None, None\n",
    "    if not isinstance(S, np.ndarray) or len(S.shape) != 3:\n",
    "        return None, None\n",
    "    if not np.isclose([np.sum(pi)], [1])[0]:\n",
    "        return None, None\n",
    "\n",
    "    n, d = X.shape\n",
    "    k = pi.shape[0]\n",
    "    if d != m.shape[1] or d != S.shape[1] or d != S.shape[2]:\n",
    "        return None, None\n",
    "    if k != m.shape[0] or k != S.shape[0]:\n",
    "        return None, None\n",
    "    \n",
    "    center_mean = m\n",
    "    covariance_mat = S\n",
    "    gauss = np.zeros((k, n))\n",
    "    \n",
    "    for i in range(k):\n",
    "        likelihood = pdf(X, center_mean[i], covariance_mat[i])\n",
    "        prior = pi[i]\n",
    "        gauss[i] = likelihood * prior\n",
    "    g = gauss / np.sum(gauss, axis=0)\n",
    "    \n",
    "    log_likelihood = np.sum(np.log(np.sum(gauss, axis=0)))\n",
    "    \n",
    "    return g, log_likelihood\n",
    "    "
   ],
   "id": "12a6054a8a5cc503",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:05.986694Z",
     "start_time": "2024-09-23T14:32:05.754255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main func\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(11)\n",
    "    a = np.random.multivariate_normal([30, 40], [[75, 5], [5, 75]], size=10000)\n",
    "    b = np.random.multivariate_normal([5, 25], [[16, 10], [10, 16]], size=750)\n",
    "    c = np.random.multivariate_normal([60, 30], [[16, 0], [0, 16]], size=750)\n",
    "    d = np.random.multivariate_normal([20, 70], [[35, 10], [10, 35]], size=1000)\n",
    "    X = np.concatenate((a, b, c, d), axis=0)\n",
    "    np.random.shuffle(X)\n",
    "    pi, m, S = initialize(X, 4)\n",
    "    g, l = expectation(X, pi, m, S)\n",
    "    print(g)\n",
    "    print(np.sum(g, axis=0))\n",
    "    print(l)"
   ],
   "id": "e5944389d4bc0558",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.98542668e-055 1.00000000e+000 1.56526421e-185 ... 1.00000000e+000\n",
      "  3.70567311e-236 1.91892348e-012]\n",
      " [6.97883333e-085 2.28658376e-279 9.28518983e-065 ... 8.12227631e-287\n",
      "  1.53690661e-032 3.17417182e-181]\n",
      " [9.79811365e-234 2.28658376e-279 2.35073465e-095 ... 1.65904890e-298\n",
      "  9.62514613e-068 5.67072057e-183]\n",
      " [1.00000000e+000 7.21133039e-186 1.00000000e+000 ... 2.42138447e-125\n",
      "  1.00000000e+000 1.00000000e+000]]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "-652797.7866541843\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Maximiliation step in the EM algorithm for a GMM\n",
    "\n",
    "* X is a numpy.ndarray of shape (n, d) containing the data set\n",
    "- g is a numpy.ndarray of shape (k, n) containing the posterior probabilities for each data point in each cluster\n",
    "* 1 loop maximum\n",
    "- Returns: pi, m, S, or None, None, None on failure\n",
    "pi is a numpy.ndarray of shape (k,) containing the updated priors for each cluster\n",
    "m is a numpy.ndarray of shape (k, d) containing the updated centroid means for each cluster\n",
    "S is a numpy.ndarray of shape (k, d, d) containing the updated covariance matrices for each\n",
    "cluster"
   ],
   "id": "e174854c029dc20a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:06.029945Z",
     "start_time": "2024-09-23T14:32:06.021583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "calculates the maximization step in the EM algorithm for a Gaussian mixture\n",
    "model\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def maximization(X, g):\n",
    "    \"\"\"\n",
    "    calculates the maximization step in the EM algorithm for a Gaussian mixture\n",
    "    model\n",
    "    \"\"\"\n",
    "    if not isinstance(X, np.ndarray) or len(X.shape) != 2:\n",
    "        return None, None, None\n",
    "    \n",
    "    n, d = X.shape\n",
    "    \n",
    "    if not isinstance(g, np.ndarray) or len(g.shape) != 2:\n",
    "        return None, None, None\n",
    "    \n",
    "    k, n1 = g.shape\n",
    "    \n",
    "    if n != n1 or np.abs(np.sum(g, axis=0) - 1).max() > 1e-10:\n",
    "        return None, None, None\n",
    "    \n",
    "    S = np.zeros((k, d, d))\n",
    "    \n",
    "    sun_g = np.sum(g, axis=1)\n",
    "    \n",
    "    pi = sun_g / n\n",
    "    m = np.dot(g, X) / sun_g[:, np.newaxis]\n",
    "    \n",
    "    for i in range(k):\n",
    "        diff = X - m[i]\n",
    "        weighted_diff = (g[i, :, np.newaxis] * diff).T\n",
    "        S[i] = np.dot(weighted_diff, diff) / sun_g[i]\n",
    "    \n",
    "    return pi, m, S\n"
   ],
   "id": "2c39794794b9d3d5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T14:32:06.339345Z",
     "start_time": "2024-09-23T14:32:06.101104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# main func\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(11)\n",
    "    a = np.random.multivariate_normal([30, 40], [[75, 5], [5, 75]], size=10000)\n",
    "    b = np.random.multivariate_normal([5, 25], [[16, 10], [10, 16]], size=750)\n",
    "    c = np.random.multivariate_normal([60, 30], [[16, 0], [0, 16]], size=750)\n",
    "    d = np.random.multivariate_normal([20, 70], [[35, 10], [10, 35]], size=1000)\n",
    "    X = np.concatenate((a, b, c, d), axis=0)\n",
    "    np.random.shuffle(X)\n",
    "    pi, m, S = initialize(X, 4)\n",
    "    g, _ = expectation(X, pi, m, S)\n",
    "    pi, m, S = maximization(X, g)\n",
    "    print(pi)\n",
    "    print(m)\n",
    "    print(S)"
   ],
   "id": "f11baac0bc90ecd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10104901 0.24748822 0.1193333  0.53212947]\n",
      "[[54.7440558  31.80888393]\n",
      " [16.84099873 31.20560148]\n",
      " [21.42588061 65.51441875]\n",
      " [32.33208369 41.80830251]]\n",
      "[[[64.05063663 -2.13941814]\n",
      "  [-2.13941814 41.90354928]]\n",
      "\n",
      " [[72.72404579  9.96322554]\n",
      "  [ 9.96322554 53.05035303]]\n",
      "\n",
      " [[46.20933259  1.08979413]\n",
      "  [ 1.08979413 66.9841323 ]]\n",
      "\n",
      " [[35.04054823 -0.94790014]\n",
      "  [-0.94790014 45.14948772]]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Task 9, Bayesian information Criterion\n",
    "\n",
    "* X is a numpy.ndarray of shape (n, d) containing the data set\n",
    "- kmin is a positive integer containing the minimum number of clusters to check for (inclusive)\n",
    "* kmax is a positive integer containing the maximum number of clusters to check for (inclusive)\n",
    "\n",
    "If kmax is None, kmax should be set to the maximum number of clusters possible\n",
    "- iterations is a positive integer containing the maximum number of iterations for the EM algorithm\n",
    "* tol is a non-negative float containing the tolerance for the EM algorithm\n",
    "- verbose is a boolean that determines if the EM algorithm should print information to the standard output\n",
    "* Returns: best_k, best_result, l, b, or None, None, None, None on failure\n",
    "\n",
    "best_k is the best value for k based on its BIC\n",
    "best_result is tuple containing pi, m, S\n",
    "pi is a numpy.ndarray of shape (k,) containing the cluster priors for the best number of clusters\n",
    "m is a numpy.ndarray of shape (k, d) containing the centroid means for the best number of clusters\n",
    "S is a numpy.ndarray of shape (k, d, d) containing the covariance matrices for the best number of clusters\n",
    "l is a numpy.ndarray of shape (kmax - kmin + 1) containing the log likelihood for each cluster size tested\n",
    "b is a numpy.ndarray of shape (kmax - kmin + 1) containing the BIC value for each cluster size tested\n",
    "Use: BIC = p * ln(n) - 2 * l\n",
    "p is the number of parameters required for the model\n",
    "n is the number of data points used to create the model\n",
    "l is the log likelihood of the model"
   ],
   "id": "9ff560ab81cdbbce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "finds the best number of clusters for GMM using the Bayesian information\n",
    "Criterion\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "expectation_maximization = __import__('8-EM').expectation_maximization\n",
    "\n",
    "\n",
    "def BIC(X, kmin=1, kmax=None, iterations=1000, tol=1e-5, verbose=False):\n",
    "    \"\"\"\n",
    "    finds the best number of clusters for GMM using the Bayesian information\n",
    "    Criterion\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if kmax == 1:\n",
    "            return None, None, None, None\n",
    "        n, d = X.shape\n",
    "        if kmax is None:\n",
    "            kmax = n\n",
    "            if kmax >= kmin:\n",
    "                return  None, None, None, None\n",
    "        \n",
    "        k_hist = list(range(kmin, kmax + 1))\n",
    "        results_hist = []\n",
    "        lh_hist = []\n",
    "        bic_hist = []\n",
    "        \n",
    "        for k in range(kmin, kmax + 1):\n",
    "            pi, m, S, g, lh = expectation_maximization(X, k, iterations, tol,\n",
    "                                                       verbose)\n",
    "        \n",
    "            if pi is None or m is None or S is None or g is None or lh is None:\n",
    "                return None, None, None, None\n",
    "        \n",
    "            num_parameters = k + k * d + k * d * (d + 1) // 2 - 1\n",
    "            bic = num_parameters * np.log(n) - 2 * lh\n",
    "        \n",
    "            lh_hist.append(lh)\n",
    "            results_hist.append((pi, m, S))\n",
    "            bic_hist.append(bic)\n",
    "    \n",
    "            min_bic_index = np.argmin(bic_hist)\n",
    "            best_k = k_hist[min_bic_index]\n",
    "            best_result = results_hist[min_bic_index]\n",
    "    \n",
    "            return best_k, best_result, np.array(lh_hist), np.array(bic_hist)\n",
    "        \n",
    "    except Exception:\n",
    "        return None, None, None, None"
   ],
   "id": "bc4b65cc3d3d2cae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
