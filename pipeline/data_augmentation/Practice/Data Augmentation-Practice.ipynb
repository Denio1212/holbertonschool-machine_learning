{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1df593",
   "metadata": {},
   "source": [
    "<img src=\"../../../figs/holberton_logo.png\" alt=\"logo\" width=\"500\"/>\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "Starting a machine learning project is exciting, but **finding enough data can be tough**. Many datasets have only a few hundred images, while big ones have tens of thousands or more.\n",
    "\n",
    "You might worry that your neural network won't perform well with so little data. But fear not! Data augmentation can help.\n",
    "\n",
    "First things first. Let's understand why it's crucial.\n",
    "\n",
    "<img src=\"img/dataaug.png\" alt=\"data augmentation\" width=\"500\"/>\n",
    "\n",
    "When you train a machine learning model, what you’re really doing is tuning its parameters such that it can map a particular input (say, an image) to some output (a label). Our optimization goal is to chase that sweet spot where our model’s loss is low, which happens when your parameters are tuned in the right way.\n",
    "\n",
    "<blockquote style=\"font-size:22px;\">Neural networks typically have parameters in the order of millions!</blockquote>\n",
    "\n",
    "Naturally, if you have **a lot of parameters, you would need to show your machine learning model a proportional amount of examples**, to get good performance. Also, the number of parameters you need is proportional to the complexity of the task your model has to perform.\n",
    "\n",
    "<blockquote style=\"font-size:22px;\">How do I get more data, if I don’t have “more data”?</blockquote>\n",
    "\n",
    "<img src=\"img/decision.gif\" alt=\"get data\" width=\"300\"/>\n",
    "\n",
    "You don't need to hunt for novel new images that can be added to your dataset. Why? Because, neural networks aren’t smart to begin with. For instance, a poorly trained neural network would think that these three tennis balls shown below, are distinct, unique images.\n",
    "\n",
    "<img src=\"img/tenis.jpeg\" alt=\"new data\" width=\"700\"/>\n",
    "\n",
    "\n",
    "So, to get more data, we just need to make minor alterations to our existing dataset. Minor changes such as flips or translations or rotations. Our neural network would think these are distinct images anyway.\n",
    "\n",
    "\n",
    "<img src=\"img/dataaugment.png\" alt=\"new data\" width=\"800\"/>\n",
    "\n",
    "A convolutional neural network that can robustly classify objects even if its placed in different orientations is said to have the property called invariance. More specifically, **a CNN can be invariant to translation, viewpoint, size or illumination (Or a combination of the above)**.\n",
    "\n",
    "This essentially is the **premise of data augmentation**. In the real world scenario, we may have a dataset of images taken in a limited set of conditions. But, our target application may exist in a variety of conditions, such as different orientation, location, scale, brightness etc. We account for these situations by training our neural network with additional synthetically modified data.\n",
    "\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Before we dive into the various augmentation techniques, there’s one issue that we must consider beforehand.\n",
    "\n",
    "### Where do we augment data in our ML pipeline?\n",
    "\n",
    "The answer may seem quite obvious; **we do augmentation before we feed the data to the model** right? Yes, but you have two options here. \n",
    "\n",
    "- One option is to perform all the necessary transformations beforehand, essentially increasing the size of your dataset. \n",
    "- The other option is to perform these transformations on a mini-batch, just before feeding it to your machine learning model.\n",
    "\n",
    "The first option is known as **offline augmentation**. This method is preferred for relatively smaller datasets, as you would end up increasing the size of the dataset by a factor equal to the number of transformations you perform (For example, by flipping all my images, I would increase the size of my dataset by a factor of 2).\n",
    "\n",
    "The second option is known as **online augmentation**, or augmentation on the fly. This method is preferred for larger datasets, as you can’t afford the explosive increase in size. Instead, you would perform transformations on the mini-batches that you would feed to your model. Some machine learning frameworks have support for online augmentation, which can be accelerated on the GPU.\n",
    "\n",
    "\n",
    "### Most common data augmentation techniques\n",
    "\n",
    "#### Flip\n",
    "This technique involves horizontally or vertically flipping images. Horizontal flipping reflects the image around the y-axis, while vertical flipping reflects it around the x-axis. It helps in increasing the diversity of the dataset and making models more robust to different orientations of objects.\n",
    "\n",
    "#### Rotation\n",
    "Rotation involves rotating images by a certain angle, typically in degrees. This technique is used to simulate variations in object orientation within images. By rotating images, models can learn to recognize objects from different perspectives, thus improving generalization.\n",
    "\n",
    "#### Scale\n",
    "Scaling modifies the size of an image by stretching or shrinking it along its dimensions. It helps simulate variations in the size of objects in the scene. By training on scaled images, models become more tolerant to variations in object size and better generalize to objects of different scales.\n",
    "\n",
    "#### Crop\n",
    "Cropping involves removing parts of the image, usually from the edges, to focus on specific regions of interest. It helps in training models to focus on important features while ignoring irrelevant background information. Cropping also introduces variations in object location within the image.\n",
    "\n",
    "#### Translation\n",
    "Translation shifts the image along its x and y axes, effectively moving objects within the image. This technique is used to simulate variations in object position and helps models learn to recognize objects regardless of their location within the image.\n",
    "\n",
    "#### Hue\n",
    "Hue adjustment involves changing the color hue of the image, typically by shifting the hue values of pixels. It helps in simulating changes in lighting conditions and variations in color appearance. By training on images with adjusted hues, models become more robust to changes in lighting and color variations in real-world scenarios"
   ]
  },
  {
   "cell_type": "code",
   "id": "76dbdf10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:03:34.792219Z",
     "start_time": "2024-05-20T15:03:34.716106Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
    "\n",
    "# Load the image\n",
    "image_path = \"/images/simpsons.jpeg\"\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image, channels=3) \n",
    "\n",
    "# Define data augmentation operations\n",
    "\n",
    "# 1. FLIP\n",
    "flip_horizontally = tf.image.flip_left_right(image)\n",
    "flip_vertically = tf.image.flip_up_down(image)\n",
    "\n",
    "# 2. ROTATE\n",
    "rotate = tf.image.rot90(image)\n",
    "\n",
    "# 3. SCALE\n",
    "scale = tf.image.resize(image, [int(image.shape[0] * 1.5), int(image.shape[1] * 1.5)])  # Scale by 1.5 times\n",
    "\n",
    "# 4. CROP\n",
    "crop = tf.image.random_crop(image, size=[200, 200, 3])  # Crop to 200x200 pixels\n",
    "\n",
    "# 5. TRANSLATE\n",
    "translate = apply_affine_transform(image.numpy(), tx=10, ty=50)  # Translate by 50 pixels in x and y directions\n",
    "\n",
    "# 6. HUE\n",
    "hue = tf.image.adjust_hue(image, delta=0.1)  # Increase hue by 0.1\n",
    "\n",
    "# Plot the original and augmented images\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.title(\"Horizontally Flipped\")\n",
    "plt.imshow(flip_horizontally.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.title(\"Vertically Flipped\")\n",
    "plt.imshow(flip_vertically.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.title(\"Rotated\")\n",
    "plt.imshow(rotate.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.title(\"Scaled\")\n",
    "plt.imshow(scale.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 6)\n",
    "plt.title(\"Cropped\")\n",
    "plt.imshow(crop.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 7)\n",
    "plt.title(\"Translated\")\n",
    "plt.imshow(translate.astype(\"uint8\"))\n",
    "\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.title(\"Hue Adjusted\")\n",
    "plt.imshow(hue.numpy().astype(\"uint8\"))\n",
    "\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "{{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /images/simpsons.jpeg : The system cannot find the path specified.\r\n; No such process [Op:ReadFile]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Load the image\u001B[39;00m\n\u001B[0;32m      7\u001B[0m image_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/images/simpsons.jpeg\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 8\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m image \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mdecode_jpeg(image, channels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m) \n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Define data augmentation operations\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# 1. FLIP\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\io_ops.py:134\u001B[0m, in \u001B[0;36mread_file\u001B[1;34m(filename, name)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mio.read_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mio.read_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread_file\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_file\u001B[39m(filename, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     99\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Reads the contents of file.\u001B[39;00m\n\u001B[0;32m    100\u001B[0m \n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m  This operation returns a tensor with the entire contents of the input\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m    A tensor of dtype \"string\", with the file contents.\u001B[39;00m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 134\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_io_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:583\u001B[0m, in \u001B[0;36mread_file\u001B[1;34m(filename, name)\u001B[0m\n\u001B[0;32m    581\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 583\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mread_file_eager_fallback\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    584\u001B[0m \u001B[43m      \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_ctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    585\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_SymbolicException:\n\u001B[0;32m    586\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# Add nodes to the TensorFlow graph.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py:606\u001B[0m, in \u001B[0;36mread_file_eager_fallback\u001B[1;34m(filename, name, ctx)\u001B[0m\n\u001B[0;32m    604\u001B[0m _inputs_flat \u001B[38;5;241m=\u001B[39m [filename]\n\u001B[0;32m    605\u001B[0m _attrs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 606\u001B[0m _result \u001B[38;5;241m=\u001B[39m \u001B[43m_execute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadFile\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_inputs_flat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    607\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_attrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    608\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _execute\u001B[38;5;241m.\u001B[39mmust_record_gradient():\n\u001B[0;32m    609\u001B[0m   _execute\u001B[38;5;241m.\u001B[39mrecord_gradient(\n\u001B[0;32m    610\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadFile\u001B[39m\u001B[38;5;124m\"\u001B[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mNotFoundError\u001B[0m: {{function_node __wrapped__ReadFile_device_/job:localhost/replica:0/task:0/device:CPU:0}} NewRandomAccessFile failed to Create/Open: /images/simpsons.jpeg : The system cannot find the path specified.\r\n; No such process [Op:ReadFile]"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "4e2514bc",
   "metadata": {},
   "source": [
    "## Project Tasks"
   ]
  },
  {
   "cell_type": "code",
   "id": "19f86820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:08:14.884224Z",
     "start_time": "2024-05-20T15:06:04.938172Z"
    }
   },
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Load the Stanford Dogs dataset\n",
    "doggies = tfds.load('stanford_dogs', split='train', as_supervised=True)\n",
    "sys.setrecursionlimit(1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\User\\tensorflow_datasets\\stanford_dogs\\0.2.0...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1ed45e0213c4b8e8953b32d4b13d4c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f0ff1245e1548f49fd762008957b593"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRecursionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mset_seed(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Load the Stanford Dogs dataset\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m doggies \u001B[38;5;241m=\u001B[39m \u001B[43mtfds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstanford_dogs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_supervised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m sys\u001B[38;5;241m.\u001B[39msetrecursionlimit(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:168\u001B[0m, in \u001B[0;36m_FunctionDecorator.__call__\u001B[1;34m(self, function, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    166\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_call()\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 168\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    170\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:649\u001B[0m, in \u001B[0;36mload\u001B[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001B[0m\n\u001B[0;32m    530\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001B[39;00m\n\u001B[0;32m    531\u001B[0m \n\u001B[0;32m    532\u001B[0m \u001B[38;5;124;03m`tfds.load` is a convenience method that:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    641\u001B[0m \u001B[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001B[39;00m\n\u001B[0;32m    642\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    643\u001B[0m dbuilder \u001B[38;5;241m=\u001B[39m _fetch_builder(\n\u001B[0;32m    644\u001B[0m     name,\n\u001B[0;32m    645\u001B[0m     data_dir,\n\u001B[0;32m    646\u001B[0m     builder_kwargs,\n\u001B[0;32m    647\u001B[0m     try_gcs,\n\u001B[0;32m    648\u001B[0m )\n\u001B[1;32m--> 649\u001B[0m \u001B[43m_download_and_prepare_builder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdbuilder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    651\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m as_dataset_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    652\u001B[0m   as_dataset_kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:508\u001B[0m, in \u001B[0;36m_download_and_prepare_builder\u001B[1;34m(dbuilder, download, download_and_prepare_kwargs)\u001B[0m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m    507\u001B[0m   download_and_prepare_kwargs \u001B[38;5;241m=\u001B[39m download_and_prepare_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m--> 508\u001B[0m   \u001B[43mdbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:168\u001B[0m, in \u001B[0;36m_FunctionDecorator.__call__\u001B[1;34m(self, function, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    166\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_call()\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 168\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    170\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:691\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[1;34m(self, download_dir, download_config, file_format)\u001B[0m\n\u001B[0;32m    689\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mread_from_directory(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_dir)\n\u001B[0;32m    690\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 691\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    692\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    693\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    694\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    696\u001B[0m   \u001B[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001B[39;00m\n\u001B[0;32m    697\u001B[0m   \u001B[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001B[39;00m\n\u001B[0;32m    698\u001B[0m   \u001B[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001B[39;00m\n\u001B[0;32m    699\u001B[0m   \u001B[38;5;66;03m# when reading from package data.\u001B[39;00m\n\u001B[0;32m    700\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdownload_size \u001B[38;5;241m=\u001B[39m dl_manager\u001B[38;5;241m.\u001B[39mdownloaded_size\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1547\u001B[0m, in \u001B[0;36mGeneratorBasedBuilder._download_and_prepare\u001B[1;34m(self, dl_manager, download_config)\u001B[0m\n\u001B[0;32m   1545\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1546\u001B[0m   optional_pipeline_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m-> 1547\u001B[0m split_generators \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_split_generators\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=unexpected-keyword-arg\u001B[39;49;00m\n\u001B[0;32m   1548\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptional_pipeline_kwargs\u001B[49m\n\u001B[0;32m   1549\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1550\u001B[0m \u001B[38;5;66;03m# TODO(tfds): Could be removed once all datasets are migrated.\u001B[39;00m\n\u001B[0;32m   1551\u001B[0m \u001B[38;5;66;03m# https://github.com/tensorflow/datasets/issues/2537\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;66;03m# Legacy mode (eventually convert list[SplitGeneratorLegacy] -> dict)\u001B[39;00m\n\u001B[0;32m   1553\u001B[0m split_generators \u001B[38;5;241m=\u001B[39m split_builder\u001B[38;5;241m.\u001B[39mnormalize_legacy_split_generators(\n\u001B[0;32m   1554\u001B[0m     split_generators\u001B[38;5;241m=\u001B[39msplit_generators,\n\u001B[0;32m   1555\u001B[0m     generator_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_examples,\n\u001B[0;32m   1556\u001B[0m     is_beam\u001B[38;5;241m=\u001B[39m\u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, BeamBasedBuilder),\n\u001B[0;32m   1557\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\datasets\\stanford_dogs\\stanford_dogs_dataset_builder.py:61\u001B[0m, in \u001B[0;36mBuilder._split_generators\u001B[1;34m(self, dl_manager)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_split_generators\u001B[39m(\u001B[38;5;28mself\u001B[39m, dl_manager):\n\u001B[1;32m---> 61\u001B[0m   images_path \u001B[38;5;241m=\u001B[39m \u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_IMAGES_URL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m   split_path, annotation_path \u001B[38;5;241m=\u001B[39m dl_manager\u001B[38;5;241m.\u001B[39mdownload_and_extract(\n\u001B[0;32m     63\u001B[0m       [_SPLIT_URL, _ANNOTATIONS_URL]\n\u001B[0;32m     64\u001B[0m   )\n\u001B[0;32m     65\u001B[0m   xml_file_list \u001B[38;5;241m=\u001B[39m collections\u001B[38;5;241m.\u001B[39mdefaultdict(\u001B[38;5;28mstr\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:601\u001B[0m, in \u001B[0;36mDownloadManager.download\u001B[1;34m(self, url_or_urls)\u001B[0m\n\u001B[0;32m    599\u001B[0m \u001B[38;5;66;03m# Add progress bar to follow the download state\u001B[39;00m\n\u001B[0;32m    600\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_downloader\u001B[38;5;241m.\u001B[39mtqdm():\n\u001B[1;32m--> 601\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_map_promise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl_or_urls\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:831\u001B[0m, in \u001B[0;36m_map_promise\u001B[1;34m(map_fn, all_inputs)\u001B[0m\n\u001B[0;32m    827\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001B[39;00m\n\u001B[0;32m    828\u001B[0m all_promises \u001B[38;5;241m=\u001B[39m tree_utils\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[0;32m    829\u001B[0m     map_fn, all_inputs\n\u001B[0;32m    830\u001B[0m )  \u001B[38;5;66;03m# Apply the function\u001B[39;00m\n\u001B[1;32m--> 831\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mtree_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_structure\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_promises\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Wait promises\u001B[39;00m\n\u001B[0;32m    834\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tree\\__init__.py:428\u001B[0m, in \u001B[0;36mmap_structure\u001B[1;34m(func, *structures, **kwargs)\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m other \u001B[38;5;129;01min\u001B[39;00m structures[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[0;32m    426\u001B[0m   assert_same_structure(structures[\u001B[38;5;241m0\u001B[39m], other, check_types\u001B[38;5;241m=\u001B[39mcheck_types)\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m unflatten_as(structures[\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m--> 428\u001B[0m                     [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m args \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mmap\u001B[39m(flatten, structures))])\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:832\u001B[0m, in \u001B[0;36m_map_promise.<locals>.<lambda>\u001B[1;34m(p)\u001B[0m\n\u001B[0;32m    827\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001B[39;00m\n\u001B[0;32m    828\u001B[0m all_promises \u001B[38;5;241m=\u001B[39m tree_utils\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[0;32m    829\u001B[0m     map_fn, all_inputs\n\u001B[0;32m    830\u001B[0m )  \u001B[38;5;66;03m# Apply the function\u001B[39;00m\n\u001B[0;32m    831\u001B[0m res \u001B[38;5;241m=\u001B[39m tree_utils\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[1;32m--> 832\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m p: \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, all_promises\n\u001B[0;32m    833\u001B[0m )  \u001B[38;5;66;03m# Wait promises\u001B[39;00m\n\u001B[0;32m    834\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\promise\\promise.py:512\u001B[0m, in \u001B[0;36mPromise.get\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    510\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_target()\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait(timeout \u001B[38;5;129;01mor\u001B[39;00m DEFAULT_TIMEOUT)\n\u001B[1;32m--> 512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_target_settled_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_raise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\promise\\promise.py:516\u001B[0m, in \u001B[0;36mPromise._target_settled_value\u001B[1;34m(self, _raise)\u001B[0m\n\u001B[0;32m    514\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_target_settled_value\u001B[39m(\u001B[38;5;28mself\u001B[39m, _raise\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    515\u001B[0m     \u001B[38;5;66;03m# type: (bool) -> Any\u001B[39;00m\n\u001B[1;32m--> 516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_settled_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_raise\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\promise\\promise.py:226\u001B[0m, in \u001B[0;36mPromise._settled_value\u001B[1;34m(self, _raise)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _raise:\n\u001B[0;32m    225\u001B[0m     raise_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fulfillment_handler0\n\u001B[1;32m--> 226\u001B[0m     \u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mraise_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraise_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_traceback\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fulfillment_handler0\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\six.py:719\u001B[0m, in \u001B[0;36mreraise\u001B[1;34m(tp, value, tb)\u001B[0m\n\u001B[0;32m    717\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[0;32m    718\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[1;32m--> 719\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\n\u001B[0;32m    720\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    721\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\promise\\promise.py:87\u001B[0m, in \u001B[0;36mtry_catch\u001B[1;34m(handler, *args, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtry_catch\u001B[39m(handler, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# type: (Callable, Any, Any) -> Union[Tuple[Any, None], Tuple[None, Tuple[Exception, Optional[TracebackType]]]]\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 87\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[43mhandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     89\u001B[0m         tb \u001B[38;5;241m=\u001B[39m exc_info()[\u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:408\u001B[0m, in \u001B[0;36mDownloadManager._download.<locals>.<lambda>\u001B[1;34m(dl_result)\u001B[0m\n\u001B[0;32m    402\u001B[0m   future \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_downloader\u001B[38;5;241m.\u001B[39mdownload(\n\u001B[0;32m    403\u001B[0m       url, download_tmp_dir, verify\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verify_ssl\n\u001B[0;32m    404\u001B[0m   )\n\u001B[0;32m    406\u001B[0m \u001B[38;5;66;03m# Post-process the result\u001B[39;00m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m future\u001B[38;5;241m.\u001B[39mthen(\n\u001B[1;32m--> 408\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m dl_result: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_register_or_validate_checksums\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=g-long-lambda\u001B[39;49;00m\n\u001B[0;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomputed_url_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_result\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexpected_url_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpected_url_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchecksum_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchecksum_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    416\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:473\u001B[0m, in \u001B[0;36mDownloadManager._register_or_validate_checksums\u001B[1;34m(self, path, url, expected_url_info, computed_url_info, checksum_path, url_path)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    456\u001B[0m   \u001B[38;5;66;03m# Eventually validate checksums\u001B[39;00m\n\u001B[0;32m    457\u001B[0m   \u001B[38;5;66;03m# Note:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    463\u001B[0m   \u001B[38;5;66;03m#   download). This is expected as it might mean the downloaded file\u001B[39;00m\n\u001B[0;32m    464\u001B[0m   \u001B[38;5;66;03m#   was corrupted. Note: The tmp file isn't deleted to allow inspection.\u001B[39;00m\n\u001B[0;32m    465\u001B[0m   _validate_checksums(\n\u001B[0;32m    466\u001B[0m       url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    467\u001B[0m       path\u001B[38;5;241m=\u001B[39mpath,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    470\u001B[0m       force_checksums_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_force_checksums_validation,\n\u001B[0;32m    471\u001B[0m   )\n\u001B[1;32m--> 473\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_rename_and_get_final_dl_path\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    475\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexpected_url_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpected_url_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcomputed_url_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomputed_url_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchecksum_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchecksum_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:497\u001B[0m, in \u001B[0;36mDownloadManager._rename_and_get_final_dl_path\u001B[1;34m(self, url, path, expected_url_info, computed_url_info, checksum_path, url_path)\u001B[0m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Eventually rename the downloaded file if checksums were recorded.\"\"\"\u001B[39;00m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;66;03m# `path` can be:\u001B[39;00m\n\u001B[0;32m    493\u001B[0m \u001B[38;5;66;03m# * Manually downloaded\u001B[39;00m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;66;03m# * (cached) checksum_path\u001B[39;00m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;66;03m# * (cached) url_path\u001B[39;00m\n\u001B[0;32m    496\u001B[0m \u001B[38;5;66;03m# * `tmp_dir/file` (downloaded path)\u001B[39;00m\n\u001B[1;32m--> 497\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_manual_dir \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_relative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_manual_dir\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m path  \u001B[38;5;66;03m# Manually downloaded data\u001B[39;00m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m path \u001B[38;5;241m==\u001B[39m checksum_path:  \u001B[38;5;66;03m# Path already at final destination\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001B[0m, in \u001B[0;36mPath.is_relative_to\u001B[1;34m(self, *other)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:679\u001B[0m, in \u001B[0;36mPurePath.relative_to\u001B[1;34m(self, other, walk_up, *_deprecated)\u001B[0m\n\u001B[0;32m    677\u001B[0m other \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_segments(other, \u001B[38;5;241m*\u001B[39m_deprecated)\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, path \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m([other] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(other\u001B[38;5;241m.\u001B[39mparents)):\n\u001B[1;32m--> 679\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_relative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    680\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    681\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m walk_up:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001B[0m, in \u001B[0;36mPath.is_relative_to\u001B[1;34m(self, *other)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:679\u001B[0m, in \u001B[0;36mPurePath.relative_to\u001B[1;34m(self, other, walk_up, *_deprecated)\u001B[0m\n\u001B[0;32m    677\u001B[0m other \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_segments(other, \u001B[38;5;241m*\u001B[39m_deprecated)\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, path \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m([other] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(other\u001B[38;5;241m.\u001B[39mparents)):\n\u001B[1;32m--> 679\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_relative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    680\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    681\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m walk_up:\n",
      "    \u001B[1;31m[... skipping similar frames: Path.is_relative_to at line 78 (741 times), PurePath.relative_to at line 679 (740 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:679\u001B[0m, in \u001B[0;36mPurePath.relative_to\u001B[1;34m(self, other, walk_up, *_deprecated)\u001B[0m\n\u001B[0;32m    677\u001B[0m other \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_segments(other, \u001B[38;5;241m*\u001B[39m_deprecated)\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, path \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m([other] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(other\u001B[38;5;241m.\u001B[39mparents)):\n\u001B[1;32m--> 679\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_relative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    680\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    681\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m walk_up:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001B[0m, in \u001B[0;36mPath.is_relative_to\u001B[1;34m(self, *other)\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001B[39;00m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 78\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelative_to\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:677\u001B[0m, in \u001B[0;36mPurePath.relative_to\u001B[1;34m(self, other, walk_up, *_deprecated)\u001B[0m\n\u001B[0;32m    672\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msupport for supplying more than one positional argument \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    673\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto pathlib.PurePath.relative_to() is deprecated and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    674\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscheduled for removal in Python \u001B[39m\u001B[38;5;132;01m{remove}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    675\u001B[0m     warnings\u001B[38;5;241m.\u001B[39m_deprecated(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpathlib.PurePath.relative_to(*args)\u001B[39m\u001B[38;5;124m\"\u001B[39m, msg,\n\u001B[0;32m    676\u001B[0m                          remove\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m14\u001B[39m))\n\u001B[1;32m--> 677\u001B[0m other \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwith_segments\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_deprecated\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, path \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m([other] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(other\u001B[38;5;241m.\u001B[39mparents)):\n\u001B[0;32m    679\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_relative_to(path):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:385\u001B[0m, in \u001B[0;36mPurePath.with_segments\u001B[1;34m(self, *pathsegments)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwith_segments\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mpathsegments):\n\u001B[0;32m    381\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Construct a new path object from any number of path-like objects.\u001B[39;00m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;124;03m    Subclasses may override this method to customize how new path objects\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;124;03m    are created from methods like `iterdir()`.\u001B[39;00m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 385\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpathsegments\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:81\u001B[0m, in \u001B[0;36m_GPath.__new__\u001B[1;34m(cls, *parts)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m: Type[_P], \u001B[38;5;241m*\u001B[39mparts: PathLike) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _P:\n\u001B[1;32m---> 81\u001B[0m   full_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mparts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m full_path\u001B[38;5;241m.\u001B[39mstartswith(_URI_PREFIXES):\n\u001B[0;32m     83\u001B[0m     prefix, _ \u001B[38;5;241m=\u001B[39m full_path\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m://\u001B[39m\u001B[38;5;124m'\u001B[39m, maxsplit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:81\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m: Type[_P], \u001B[38;5;241m*\u001B[39mparts: PathLike) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _P:\n\u001B[1;32m---> 81\u001B[0m   full_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parts)\n\u001B[0;32m     82\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m full_path\u001B[38;5;241m.\u001B[39mstartswith(_URI_PREFIXES):\n\u001B[0;32m     83\u001B[0m     prefix, _ \u001B[38;5;241m=\u001B[39m full_path\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m://\u001B[39m\u001B[38;5;124m'\u001B[39m, maxsplit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:133\u001B[0m, in \u001B[0;36m_GPath.__fspath__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__fspath__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m--> 133\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_path_str\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:130\u001B[0m, in \u001B[0;36m_GPath._path_str\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    128\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_PATH\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muri_scheme\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m://\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparts[\u001B[38;5;241m2\u001B[39m:])\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 130\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_PATH\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparts\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparts \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32m<frozen ntpath>:121\u001B[0m, in \u001B[0;36mjoin\u001B[1;34m(path, *paths)\u001B[0m\n",
      "\u001B[1;31mRecursionError\u001B[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "85f8501b",
   "metadata": {},
   "source": [
    "### 0. Flip\n",
    "\n",
    "Write a function `def flip_image(image)`: that flips an image horizontally:\n",
    "\n",
    "- image is a `3D tf.Tensor` containing the image to flip\n",
    "- Returns the flipped image"
   ]
  },
  {
   "cell_type": "code",
   "id": "b2b7acc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:04:07.716066Z",
     "start_time": "2024-05-20T15:04:07.709257Z"
    }
   },
   "source": [
    "def flip_image(image):\n",
    "    flipped = tf.image.flip_left_right(image)\n",
    "    return flipped"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "babed21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:04:08.085881Z",
     "start_time": "2024-05-20T15:04:08.064144Z"
    }
   },
   "source": [
    "# Shuffle and take one example from the dataset\n",
    "for image, _ in doggies.shuffle(10).take(1):\n",
    "    flipped_image = flip_image(image)\n",
    "    \n",
    "    # Plot the original and flipped images\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Flipped Image\")\n",
    "    plt.imshow(flipped_image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.show()\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doggies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Shuffle and take one example from the dataset\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdoggies\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      3\u001B[0m     flipped_image \u001B[38;5;241m=\u001B[39m flip_image(image)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# Plot the original and flipped images\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'doggies' is not defined"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "84fb311f",
   "metadata": {},
   "source": [
    "### 1. Crop\n",
    "\n",
    "Write a function `def crop_image(image, size)`: that performs a random crop of an image:\n",
    "\n",
    "- image is a `3D tf.Tensor` containing the image to crop\n",
    "- `size` is a tuple containing the size of the crop\n",
    "- Returns the cropped image"
   ]
  },
  {
   "cell_type": "code",
   "id": "4dba0dde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:09:40.387734Z",
     "start_time": "2024-05-20T15:09:40.382992Z"
    }
   },
   "source": [
    "def crop_image(image, size):\n",
    "    return tf.image.random_crop(image, size=size)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "1a0e2bea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:09:44.744548Z",
     "start_time": "2024-05-20T15:09:44.722298Z"
    }
   },
   "source": [
    "crop_size = (200, 200, 3)\n",
    "\n",
    "# Shuffle and take one example from the dataset\n",
    "for image, _ in doggies.shuffle(10).take(1):\n",
    "    cropped_image = crop_image(image, crop_size)\n",
    "    \n",
    "    # Plot the original and cropped images\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Cropped Image\")\n",
    "    plt.imshow(cropped_image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doggies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m crop_size \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m3\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Shuffle and take one example from the dataset\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdoggies\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      5\u001B[0m     cropped_image \u001B[38;5;241m=\u001B[39m crop_image(image, crop_size)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Plot the original and cropped images\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'doggies' is not defined"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "67394c2c",
   "metadata": {},
   "source": [
    "### 2. Rotate\n",
    "\n",
    "Write a function `def rotate_image(image)`: that rotates an image by 90 degrees counter-clockwise:\n",
    "\n",
    "- image is a `3D tf.Tensor` containing the image to rotate\n",
    "- Returns the rotated image"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0c0023f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:10:33.621740Z",
     "start_time": "2024-05-20T15:10:33.612638Z"
    }
   },
   "source": [
    "def rotate_image(image):\n",
    "    return tf.image.rot90(image)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "472cf1cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T14:52:44.725851Z",
     "start_time": "2024-05-20T14:52:44.707332Z"
    }
   },
   "source": [
    "# Shuffle and take one example from the dataset\n",
    "for image, _ in doggies.shuffle(10).take(1):\n",
    "    rotated_image = rotate_image(image)\n",
    "    \n",
    "    # Plot the original and rotated images\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Rotated Image\")\n",
    "    plt.imshow(rotated_image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doggies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Shuffle and take one example from the dataset\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdoggies\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      3\u001B[0m     rotated_image \u001B[38;5;241m=\u001B[39m rotate_image(image)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# Plot the original and rotated images\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'doggies' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "3c28a22c",
   "metadata": {},
   "source": [
    "### 3. Shear\n",
    "\n",
    "Write a function `def shear_image(image, intensity)`: that randomly shears an image:\n",
    "\n",
    "- `image` is a `3D tf.Tensor` containing the image to shear\n",
    "- `intensity` is the intensity with which the image should be sheared\n",
    "- Returns the sheared image"
   ]
  },
  {
   "cell_type": "code",
   "id": "58ba9785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:12:37.659882Z",
     "start_time": "2024-05-20T15:12:37.653721Z"
    }
   },
   "source": [
    "def shear_image(image, intensity):\n",
    "    image_nparray = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    tf.keras.preprocessing.image.random_shear(image_nparray)\n",
    "    return tf.keras.preprocessing.image.array_to_img(image_nparray)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "cb1d042c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T14:52:44.813332Z",
     "start_time": "2024-05-20T14:52:44.791800Z"
    }
   },
   "source": [
    "shear_intensity = 2.5\n",
    "\n",
    "# Shuffle and take one example from the dataset\n",
    "for image, _ in doggies.shuffle(10).take(1):\n",
    "    sheared_image = shear_image(image, shear_intensity)\n",
    "    \n",
    "    # Plot the original and sheared images\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Sheared Image\")\n",
    "    plt.imshow(sheared_image)\n",
    "    \n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doggies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m shear_intensity \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2.5\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Shuffle and take one example from the dataset\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdoggies\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      5\u001B[0m     sheared_image \u001B[38;5;241m=\u001B[39m shear_image(image, shear_intensity)\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;66;03m# Plot the original and sheared images\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'doggies' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "47716ee9",
   "metadata": {},
   "source": [
    "### 4. Brightness\n",
    "\n",
    "Write a function `def change_brightness(image, max_delta)`: that randomly changes the brightness of an image:\n",
    "\n",
    "- `image` is a `3D tf.Tensor` containing the image to change\n",
    "- `max_delta` is the maximum amount the image should be brightened (or darkened)\n",
    "- Returns the altered image"
   ]
  },
  {
   "cell_type": "code",
   "id": "59711ce8",
   "metadata": {},
   "source": [
    "def change_brightness(image, max_delta):\n",
    "    return tf.keras.preprocessing.image.random_brightness(image, max_delta)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8ca50ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T14:52:44.854215Z",
     "start_time": "2024-05-20T14:52:44.831917Z"
    }
   },
   "source": [
    "# Define the maximum delta for brightness change\n",
    "max_delta = 0.3\n",
    "\n",
    "# Shuffle and take one example from the dataset\n",
    "for image, _ in doggies.shuffle(10).take(1):\n",
    "    altered_image = change_brightness(image, max_delta)\n",
    "    \n",
    "    # Plot the original and altered images\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Altered Image\")\n",
    "    plt.imshow(altered_image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doggies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m max_delta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.3\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Shuffle and take one example from the dataset\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdoggies\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      6\u001B[0m     altered_image \u001B[38;5;241m=\u001B[39m change_brightness(image, max_delta)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Plot the original and altered images\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'doggies' is not defined"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "aea4c37f",
   "metadata": {},
   "source": [
    "### 5. Hue\n",
    "\n",
    "Write a function `def change_hue(image, delta)`: that changes the hue of an image:\n",
    "\n",
    "- `image` is a `3D tf.Tensor` containing the image to change\n",
    "- `delta` is the amount the hue should change\n",
    "- Returns the altered image"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8e00aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:16:48.487961Z",
     "start_time": "2024-05-20T15:16:48.482709Z"
    }
   },
   "source": [
    "def change_hue(image, delta):\n",
    "    return tf.keras.preprocessing.image.random_hue(image, delta)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "33531dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:16:49.080458Z",
     "start_time": "2024-05-20T15:16:49.047507Z"
    }
   },
   "source": [
    "# Define the delta for hue change\n",
    "hue_delta = 0.2 \n",
    "\n",
    "# Shuffle and take one example from the dataset\n",
    "for image, _ in doggies.shuffle(10).take(1):\n",
    "    altered_image = change_hue(image, hue_delta)\n",
    "    \n",
    "    # Plot the original and altered images\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Altered Image\")\n",
    "    plt.imshow(altered_image.numpy().astype(\"uint8\"))\n",
    "    \n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doggies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m hue_delta \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Shuffle and take one example from the dataset\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image, _ \u001B[38;5;129;01min\u001B[39;00m \u001B[43mdoggies\u001B[49m\u001B[38;5;241m.\u001B[39mshuffle(\u001B[38;5;241m10\u001B[39m)\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      6\u001B[0m     altered_image \u001B[38;5;241m=\u001B[39m change_hue(image, hue_delta)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# Plot the original and altered images\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'doggies' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "30be50fd",
   "metadata": {},
   "source": [
    "### Happy coding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
